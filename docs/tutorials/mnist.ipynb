{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN on MNIST\n",
    "\n",
    "This tutorial demonstrates how to build a simple convolutional neural network (CNN) with Inox, and train it to classify digits. It is intended for those who are new to JAX and Inox, or simply curious.\n",
    "\n",
    "Unlike [PyTorch](https://pytorch.org), which is a centralized framework, the [JAX](https://jax.readthedocs.io) ecosystem is distributed as a collection of packages, each tackling a well-defined task. This tutorial uses [Inox](https://inox.readthedocs.io) to build the network, [Optax](https://optax.readthedocs.io) to optimize the network, and [PyTorch](https://pytorch.org/) to load the [MNIST](https://wikipedia.org/wiki/MNIST_database) data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install jax[cpu] inox optax tqdm\n",
    "# !pip install torchvision --extra-index-url https://download.pytorch.org/whl/cpu\n",
    "\n",
    "import jax\n",
    "import inox\n",
    "import inox.nn as nn\n",
    "import optax\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms.functional import to_tensor\n",
    "from tqdm import tqdm\n",
    "\n",
    "jax.config.update('jax_platform_name', 'cpu')\n",
    "jax.numpy.set_printoptions(suppress=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "JAX does not provide built-in datasets and dataloaders, as there are already many alternatives. We load the MNIST dataset using PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = MNIST('data', train=True, download=True, transform=to_tensor)\n",
    "testset = MNIST('data', train=False, download=True)\n",
    "\n",
    "loader = DataLoader(trainset, batch_size=8, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 1, 28, 28)\n",
      "[5 4 6 3 9 5 3 7]\n"
     ]
    }
   ],
   "source": [
    "x, y = next(iter(loader))\n",
    "x, y = x.numpy(), y.numpy()\n",
    "\n",
    "print(x.shape)\n",
    "print(y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above example, `x` is a batch of black and white images and `y` is a batch of corresponding digits."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network\n",
    "\n",
    "Our network is a simple convolutional neural network. We define its architecture by a sequence of operations, often called layers. These operations do not need to be Inox modules, they can be any callables.\n",
    "\n",
    "A few remarks:\n",
    "\n",
    "1. `nn.Rearrange` is a small wrapper around [einops](https://github.com/arogozhnikov/einops)'s `rearrange`, and enables intuitive and efficient axis manipulations.\n",
    "2. Like TensorFlow, Inox adopts a channel-last convention for axes, meaning that a batch of images is expected to have a shape $(N, H, W, C)$, where $C$ is the number of channels.\n",
    "3. Some layers, like `nn.Linear` and `nn.Conv`, require a random number generator (RNG) key for initialization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, key):\n",
    "        keys = jax.random.split(key, 4)\n",
    "\n",
    "        self.layers = [\n",
    "            nn.Rearrange('C H W -> H W C'),\n",
    "            nn.Conv(keys[0], spatial=2, in_channels=1, out_channels=4),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv(keys[1], spatial=2, in_channels=4, out_channels=4),\n",
    "            nn.MaxPool(spatial=2, window_size=2),\n",
    "            nn.Rearrange('H W C -> (H W C)'),\n",
    "            nn.Linear(keys[2], in_features=576, out_features=256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(keys[3], in_features=256, out_features=10),\n",
    "        ]\n",
    "\n",
    "    def __call__(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    @jax.jit\n",
    "    def predict(self, x):\n",
    "        return jax.nn.softmax(self(x))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our network is a PyTree, that is just a nested collection of Python objects. Some of these objects are JAX arrays, like the kernel of the first convolution `network.layers[1].kernel`, while others are arbitrary objects, like the string `network.layers[0].pattern`. Inox provides a nice representation for its modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN(\n",
       "  layers = [\n",
       "    Rearrange(\n",
       "      lengths = {},\n",
       "      pattern = 'C H W -> H W C'\n",
       "    ),\n",
       "    Conv(\n",
       "      bias = float32[4],\n",
       "      dilation = [1, 1],\n",
       "      groups = 1,\n",
       "      kernel = float32[3, 3, 1, 4],\n",
       "      kernel_size = [3, 3],\n",
       "      padding = [(0, 0), (0, 0)],\n",
       "      spatial = 2,\n",
       "      stride = [1, 1]\n",
       "    ),\n",
       "    ReLU(),\n",
       "    ...,\n",
       "    Linear(\n",
       "      bias = float32[256],\n",
       "      weight = float32[576, 256]\n",
       "    ),\n",
       "    ReLU(),\n",
       "    Linear(\n",
       "      bias = float32[10],\n",
       "      weight = float32[256, 10]\n",
       "    )\n",
       "  ]\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network = CNN(jax.random.PRNGKey(0))\n",
    "network"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that our network is built, we can use it to make predictions. However, since it has not been trained yet, it is currently unable to classify the digits. In the next cell, you see that the probability it associates with each digit (0 to 9) is more or less uniform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([0.10095079, 0.09911551, 0.10107352, 0.09597864, 0.10047358,\n",
       "       0.10346892, 0.09940311, 0.09472179, 0.10336623, 0.10144799],      dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.predict(x[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can quantify the quality of our network's predictions with their [cross entropy](https://wikipedia.org/wiki/Cross_entropy). For perfect predictions, the cross entropy is null, making it a good training objective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy(f, x, y):\n",
    "    return optax.softmax_cross_entropy_with_integer_labels(\n",
    "        logits=f(x),\n",
    "        labels=y,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([2.2684839, 2.300259 , 2.234749 , 2.348772 , 2.3462443, 2.245705 ,\n",
       "       2.3467388, 2.3620248], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_entropy(jax.vmap(network), x, y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "Now that we have an objective to minimize, we can start to train the parameters $\\phi$ of our network. Inox modules have a special `partition` method which separates arrays that can be optimized, typically parameters, from those that should not. We initialize an Optax optimizer (Adam) for the parameters of our network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "params, _, _ = network.partition()\n",
    "optimizer = optax.adam(learning_rate=1e-3)\n",
    "opt_state = optimizer.init(params)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A training step consists in computing the gradients of the loss $\\ell(\\phi)$, here the cross entropy, with respect to the parameters $\\phi$ and updating the parameters according to the gradients. The whole procedure is written as a single JIT-compiled function to make it run as fast as possible. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def step(network, opt_state, x, y):\n",
    "    params, buffers, build = network.partition()\n",
    "\n",
    "    def ell(params):\n",
    "        return cross_entropy(jax.vmap(build(params, buffers)), x, y).mean()\n",
    "\n",
    "    loss, grads = jax.value_and_grad(ell)(params)\n",
    "    updates, opt_state = optimizer.update(grads, opt_state, params)\n",
    "    params = optax.apply_updates(params, updates)\n",
    "\n",
    "    return build(params, buffers), opt_state"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, to train the network, we iteratively apply our training step with random batches loaded from our training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7500/7500 [00:35<00:00, 211.81it/s]\n"
     ]
    }
   ],
   "source": [
    "for x, y in tqdm(loader):\n",
    "    x, y = x.numpy(), y.numpy()\n",
    "    network, opt_state = step(network, opt_state, x, y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "Now that the network is trained, we can use it to make predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAxUlEQVR4nGNgGDaAEUKFpD77sfTFHeyS9xQYGBg+X4UKPuk6w8DAwMDAAuGm6l/TMnSweCzLwPDntSTDozPIOhkYGBgYBA3PmDIw/Lh1XShnGi5nBP+9KIRLTuzl/2AokwlDMlv0/U1cGq1//rPDJcfQ+m83Ky45zrM/rHBqrPu3Daec9+8PlrjkhO/+W4ZLjvn0v9vKuCTV/v3zxSUn/+BfMSMuydZ//0xwydl+QpdEClsbHoa7X1AkWZA5F53f4TIWEwAAaRE8kJuHrgAAAAAASUVORK5CYII=",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, _ = testset[0]\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([0.00000007, 0.00000002, 0.00000499, 0.00000303, 0.        ,\n",
       "       0.0000001 , 0.        , 0.9999918 , 0.        , 0.00000015],      dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.predict(to_tensor(x).numpy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jax",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
